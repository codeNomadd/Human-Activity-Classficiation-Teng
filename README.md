# Human Activity Classification using TENG Sensor Data

## üìå Project Overview

This project focuses on classifying different human physical activities ‚Äî such as walking, running, and jumping ‚Äî using time-series voltage data collected from a **TENG (triboelectric nanogenerator) sensor**. The TENG sensor captures biomechanical energy generated by foot or body movements and converts it into voltage, creating a unique signal pattern for each type of motion.

The objective is to develop a lightweight machine learning pipeline that can accurately distinguish between these movement types using the captured voltage waveforms.

---

## üéØ Objectives

- Preprocess and visualize raw voltage signals from TENG sensors.
- Build a supervised learning model to classify activities:
  - **Walking**
  - **Running**
  - **Jumping**
- Evaluate model performance using appropriate metrics (accuracy, confusion matrix).
- Demonstrate the feasibility of motion classification using simple sensor signals for applications like wearable systems, smart rehabilitation, or edge computing.

---

## üìÅ Dataset

The dataset consists of `.xlsx` files stored in the `data/` directory. Each file corresponds to one trial of a specific activity and is assumed to come from a different individual. The dataset includes:

| Activity | Files |
|----------|-------|
| Walking  | `Walking.xlsx`, `Walking2.xlsx`, `Walking3.xlsx` |
| Running  | `Running.xlsx`, `Running2.xlsx`, `Running3.xlsx` |
| Jumping  | `Jumping.xlsx`, `Jumping2.xlsx`, `Jumping3.xlsx` |

Each file contains:
- **Column 1:** `Timestamp` (in seconds) ‚Äì consistent sampling across all files  
- **Column 2:** `Voltage` (in volts) ‚Äì generated by the TENG sensor in real-time during the activity

The voltage data varies in length across samples, and will be standardized during preprocessing.

---

## ‚öôÔ∏è Approach Summary

1. **Preprocessing**
   - Resample all signals to a uniform length (e.g., 1000 points)
   - Normalize voltage values (e.g., zero-mean, unit variance)
   - Assign activity labels to each file

2. **Modeling**
   - Train baseline models: Logistic Regression, Random Forest
   - Optionally explore deep learning models (1D CNN, LSTM)

3. **Evaluation**
   - Use cross-validation or hold-out testing
   - Evaluate using accuracy and confusion matrix

---

## üöÄ Final Model Strategy & Insights

### What Our Final Code Does Better
Earlier versions of our project used either short (100-point) or longer (500-point) voltage signal segments for activity classification. While these approaches achieved moderate accuracy, they struggled to generalize, especially when distinguishing between similar activities like Running and Jumping.

Our final pipeline introduces three major improvements, resulting in significantly higher accuracy and better generalization:

### 1. Combining 100-Point and 500-Point Datasets
We processed the data into both 100-point (X_100.npy) and 500-point (X_500.npy) non-overlapping windows:
- **100-point windows:** Capture fine-grained, short-term voltage dynamics (e.g., frequency of sharp spikes, useful for Running).
- **500-point windows:** Capture broader, long-term energy patterns (e.g., total signal energy, useful for distinguishing Jumping from Running).

By leveraging both, our model learns both local and global signal characteristics, improving its ability to distinguish between activities.

### 2. Insights from window_energy_boxplot.png
The boxplot of windowed signal energy (window_energy_boxplot.png) revealed:
- **Jumping** windows have the highest energy (larger peaks, more intense signals).
- **Walking** windows have consistently low energy.
- **Running** windows show intermediate and more variable energy.

This visualization guided us to engineer energy-based features, which proved crucial for separating activities with similar waveform shapes but different intensities.

### 3. Feature-Rich ML Pipeline
Our final pipeline uses a Random Forest classifier with features including:
- **Time-domain:** mean, std, max, min, skew, kurtosis, slope
- **Frequency-domain:** FFT energy, high/low band ratios
- **Shape:** peak count, zero crossings
- **Energy-based:** total energy, slope variance

We also applied data augmentation (jitter, scaling, shifting) to the training set, increasing robustness without leaking information into the test set.

### üß† Key Takeaways
- **Multi-resolution analysis:** Using both 100- and 500-point windows lets the model see both local and global patterns.
- **Domain-driven features:** Energy and frequency features, inspired by data visualization, were key to high accuracy.
- **Efficient for edge devices:** The final model is lightweight and interpretable, suitable for real-time, low-power applications.

---

## üß† Potential Applications

- Smart footwear or insole devices
- Physical rehabilitation monitoring
- Edge AI for real-time human activity recognition
- Low-power motion analysis systems

---

## üë• Contributors

- **Sensor Source:** Custom data collected using TENG-based sensing
- **Team Members:** [Irmuun]

---

## üß™ Testing Scripts

### scripts/testing/test_v5.py
- Runs `train_v5.py` 5 times with different random seeds (0‚Äì4).
- Collects and prints the accuracy for each run.
- Saves a summary of the results (including mean accuracy) to `test_v5_results.txt` in the same directory.
- **Usage:**
  ```bash
  python scripts/testing/test_v5.py
  ```

### scripts/testing/random_test.py
- For each activity (Walking, Running, Jumping), and for each of their 3 Excel files, randomly selects 3 different 500-point segments (total 27 samples).
- Uses the feature extraction and model logic from `train_v5.py` to predict the activity for each segment.
- Prints the true and predicted labels for each sample and summarizes the number of correct predictions out of 27.
- **Usage:**
  ```bash
  python scripts/testing/random_test.py
  ```

---

## üß™ Subject Generalization: LOSO Results

We evaluated our final feature-rich pipeline using Leave-One-Subject-Out (LOSO) cross-validation, where the model is trained on two subjects and tested on the third, rotating through all combinations. This tests the model's ability to generalize to unseen users.

**Results:**
- For each fold (P1, P2, P3 as test subject), the model achieved perfect accuracy:

```
LOSO Fold: Test Subject P1  Accuracy: 1.0000
LOSO Fold: Test Subject P2  Accuracy: 1.0000
LOSO Fold: Test Subject P3  Accuracy: 1.0000

Mean LOSO Accuracy: 1.0000
```

**Interpretation:**
- The model generalizes extremely well to new users, correctly classifying all activity segments for each left-out subject.
- This demonstrates the robustness of our feature engineering and pipeline for real-world, subject-independent activity recognition.
- **Notably, all three main test codes (subject-agnostic, random segment, and LOSO) achieved 100% accuracy scores, underscoring the reliability and effectiveness of our approach.**

---

## üî¨ Discussion: Techniques in train_v5.py vs train_v6.py

### train_v5.py: Subject-Agnostic, Feature-Rich Pipeline
- **Feature Engineering:**
  - Extracts a comprehensive set of features from each 500-point segment: time-domain (mean, std, max, min, skew, kurtosis, slope), frequency-domain (FFT energy, low/high band ratios), shape (peak count, zero crossings), and energy-based features.
  - Also aggregates features from 100-point windows, capturing fine-grained local signal dynamics.
  - Concatenates (fuses) features from both 500-point and 100-point windows for each sample, giving the model both global and local context.
- **Augmentation:**
  - Applies jitter, scaling, and shifting to training data, increasing robustness and helping the model generalize to new signal variations.
- **Model:**
  - Uses XGBoost (or Random Forest in some variants) for classification, leveraging the rich feature set.
- **Evaluation:**
  - Standard cross-validation or hold-out testing, mixing all subjects together (subject-agnostic split).

### train_v6.py: Subject-Aware, LOSO Generalization
- **Feature Engineering:**
  - Uses the same feature extraction and fusion as train_v5.py (500-point and 100-point features concatenated).
- **No Data Augmentation:**
  - For a fair LOSO test, no artificial augmentation is applied‚Äîonly real, subject-specific segments are used.
- **Model:**
  - Uses Random Forest for classification, but the feature pipeline is identical to train_v5.py.
- **Evaluation:**
  - Implements Leave-One-Subject-Out (LOSO) cross-validation: for each fold, trains on two subjects and tests on the third, rotating through all combinations.
  - This directly measures the model's ability to generalize to unseen users.

### Key Insights
- **Feature Fusion:** Both scripts show that combining global (500-point) and local (100-point) features is crucial for high accuracy and robust generalization.
- **Augmentation:** While augmentation helps in subject-agnostic splits (train_v5.py), it is not used in LOSO (train_v6.py) to avoid inflating generalization results.
- **Generalization:** The perfect LOSO results in train_v6.py demonstrate that the feature engineering and fusion pipeline is strong enough to generalize across subjects, not just within a mixed pool.
- **Practical Impact:** This approach is suitable for real-world deployment, where the model may encounter new users not seen during training.

---
